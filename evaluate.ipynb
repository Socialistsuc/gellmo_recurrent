{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from typing import List, Dict, Any, Tuple\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/van/Developer/workspace/gellmo/GeLLMO/data/props\n",
      "<built-in function getcwd>\n",
      "0.4334298211192694 -10.300947630755612 5.122530176377287 0.0740022497482625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sk21/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator SVC from version 0.18.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%cd data/props/\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(os.getcwd)\n",
    "from properties import drd2\n",
    "from properties import qed\n",
    "from properties import penalized_logp\n",
    "from properties import sas\n",
    "\n",
    "#print(qed(\"O=[n+]1c2c(n(O)cc3c4cc(O)ccc1c3c4)CCCCC2\"), penalized_logp(\"O=[n+]1c2c(n(O)cc3c4cc(O)ccc1c3c4)CCCCC2\"), sas(\"O=[n+]1c2c(n(O)cc3c4cc(O)ccc1c3c4)CCCCC2\"))\n",
    "print(qed(\"O=[n+]1c2c(n(O)cc3c4cc(O)ccc1c3c4)CCCCC2\"), penalized_logp(\"O=[n+]1c2c(n(O)cc3c4cc(O)ccc1c3c4)CCCCC2\"), sas(\"O=[n+]1c2c(n(O)cc3c4cc(O)ccc1c3c4)CCCCC2\"), drd2(\"O=[n+]1c2c(n(O)cc3c4cc(O)ccc1c3c4)CCCCC2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(file, data):\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "# taken from https://github.com/ziqi92/Modof/blob/main/model/properties.py#L34\n",
    "def pair_similarity(amol, bmol, sim_type):\n",
    "    if amol is None or bmol is None: \n",
    "        return 0.0\n",
    "\n",
    "    if isinstance(amol, str):\n",
    "        amol = Chem.MolFromSmiles(amol)\n",
    "    if isinstance(bmol, str):\n",
    "        bmol = Chem.MolFromSmiles(bmol)\n",
    "    if amol is None or bmol is None:\n",
    "        return 0.0\n",
    "\n",
    "    if sim_type == \"binary\":\n",
    "        fp1 = AllChem.GetMorganFingerprintAsBitVect(amol, 2, nBits=2048, useChirality=False)\n",
    "        fp2 = AllChem.GetMorganFingerprintAsBitVect(bmol, 2, nBits=2048, useChirality=False)\n",
    "    else:\n",
    "        fp1 = AllChem.GetMorganFingerprint(amol, 2, useChirality=False)\n",
    "        fp2 = AllChem.GetMorganFingerprint(bmol, 2, useChirality=False)\n",
    "\n",
    "    sim = DataStructs.TanimotoSimilarity(fp1, fp2)\n",
    "    \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FP_sim(smiles):\n",
    "    # assume there might be invalid smiles\n",
    "    mols = []\n",
    "    for smi in smiles:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        if mol:\n",
    "            mols.append(mol)\n",
    "            \n",
    "    sim = np.zeros((len(mols), len(mols)))\n",
    "    for i in range(len(mols)):\n",
    "        for j in range(i, len(mols)):\n",
    "            sim[i, j] = sim[j, i] = pair_similarity(mols[i], mols[j], \"binary\")\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_prop(val, min_val, max_val):\n",
    "    normalized_val = (val - min_val) / (max_val - min_val)\n",
    "    return max(0, min(1, normalized_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_optimized(input_prop, output_prop, property):\n",
    "    \"\"\"\n",
    "    Find the best optimized SMILES that satisfies constraints and maximizes improvement.\n",
    "    Args:\n",
    "        input_prop (dict): Properties of the input molecule.\n",
    "        output_prop (dict): Properties of the optimized molecules.\n",
    "        property (list): List of properties to optimize.\n",
    "    \n",
    "    Returns:\n",
    "        int: Index of the best optimized molecule.\n",
    "    \"\"\"\n",
    "    best_idx = None\n",
    "    best_improvement = -1\n",
    "    num_candidates = len(output_prop[property[0]])\n",
    "\n",
    "    for i in range(num_candidates):\n",
    "        improvement = 0\n",
    "        # Skip candidate if the change in property is in the wrong direction\n",
    "        wrong_direction = False\n",
    "        for prop in property:\n",
    "            input_val = input_prop[prop]\n",
    "            output_val = output_prop[prop][i]\n",
    "            #print(i, prop, input_val, output_val)\n",
    "            if prop == \"mutagenicity\":\n",
    "                if output_val >= input_val:  # Mutagenicity must decrease\n",
    "                    wrong_direction = True\n",
    "                    break\n",
    "            else:\n",
    "                if output_val <= input_val:  # Other properties must increase\n",
    "                    wrong_direction = True\n",
    "                    break\n",
    "\n",
    "        #print(wrong_direction)\n",
    "        if wrong_direction:\n",
    "            continue  # Skip this candidate\n",
    "\n",
    "        for prop in property:\n",
    "            input_val = input_prop[prop]\n",
    "            output_val = output_prop[prop][i]\n",
    "    \n",
    "            if input_val == 0:\n",
    "                improvement += output_val\n",
    "            else:\n",
    "                improvement += (output_val - input_val) / abs(input_val) if prop != 'mutagenicity' else (input_val - output_val) / abs(input_val)\n",
    "            #print(i, prop, input_prop[prop], output_prop[prop][i], improvement)\n",
    "        \n",
    "        if improvement >= best_improvement:\n",
    "            best_improvement = improvement\n",
    "            best_idx = i\n",
    "            \n",
    "    #print(f\"Best improvement: {best_improvement}, index: {best_idx}\")\n",
    "    return best_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best index: 0\n"
     ]
    }
   ],
   "source": [
    "best_idx = find_best_optimized(\n",
    "    input_prop={\"qed\": 0.5, \"bbbp\": 0.6, \"drd2\":0, \"plogp\": -3.0, \"mutagenicity\": 0.9},\n",
    "    output_prop={\n",
    "        \"qed\": [0.8, 0.7],\n",
    "        \"bbbp\": [0.7, 0.7],\n",
    "        \"drd2\": [0.1, 0.1],\n",
    "        \"plogp\": [2.0, 2.0],\n",
    "        \"mutagenicity\": [0.71, 0.6]\n",
    "    },\n",
    "    property=[\"qed\", \"bbbp\", \"drd2\", \"plogp\", \"mutagenicity\"]\n",
    ")\n",
    "print(\"Best index:\", best_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Processing properties of generated molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_props(output_smiles_path, admet_props_path, props_path):\n",
    "    \"\"\"computes the logp,qed,drd2,sas for the optimized smiles\"\"\"\n",
    "    output_smiles = []\n",
    "    with open(output_smiles_path, 'r') as f:\n",
    "        for line in f:\n",
    "            output_smiles.extend(line.strip().split(','))\n",
    "    \n",
    "    output_smiles = set(output_smiles)\n",
    "    # read the existing admet properties\n",
    "    prev_df = None\n",
    "    if os.path.exists(admet_props_path):\n",
    "        prev_df = pd.read_csv(admet_props_path)\n",
    "        prev_df.set_index('smiles', inplace=True)\n",
    "\n",
    "    #print(len(output_smiles))\n",
    "    #print(prev_df.shape, len(prev_df.index))\n",
    "\n",
    "    # compute plog, qed, drd2, sas for the optimized smiles and merge with previous properties\n",
    "    props = defaultdict(dict)\n",
    "    for smi in output_smiles:\n",
    "        if prev_df is not None and smi in prev_df.index:\n",
    "            for col in prev_df.columns:\n",
    "                props[smi][col] = prev_df.loc[smi][col]\n",
    "        elif prev_df is not None:\n",
    "            continue\n",
    "\n",
    "        if 'plogp' not in props[smi]:\n",
    "            props[smi]['plogp'] = penalized_logp(smi)\n",
    "        if 'qed' not in props[smi]:\n",
    "            props[smi]['qed'] = qed(smi)\n",
    "        if 'drd2' not in props[smi]:\n",
    "            props[smi]['drd2'] = drd2(smi)\n",
    "        if 'sas' not in props[smi]:\n",
    "            props[smi]['sas'] = sas(smi)\n",
    "    \n",
    "    #print(len(props))\n",
    "    # save the props as a dataframe\n",
    "    props_df = pd.DataFrame(props).T\n",
    "    #print(props_df.shape, len(props_df.index))\n",
    "    props_df = props_df.reset_index().rename(columns={'index': 'smiles',\n",
    "                                                      'BBBP': 'bbbp', 'AMES': 'mutagenicity', \n",
    "                                                      'HIA_Hou': 'hia'})\n",
    "    props_df = props_df.round(2)\n",
    "    #print(props_df.shape, len(props_df.index))\n",
    "    props_df.to_csv(props_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(test_data_path, output_path, \n",
    "                    seen_smiles, task,\n",
    "                    props_path,\n",
    "                    normalize = {'plogp': (-20, 10)}):\n",
    "    \"\"\"\n",
    "    Compute the metrics for the optimization task.\n",
    "    Args:\n",
    "        test_data_path (str): Path to the test data json file.\n",
    "        output_path (str): Path to the output file.\n",
    "        seen_smiles (set): Set of SMILES seen during training.\n",
    "        property (list): List of properties to optimize.\n",
    "        task (str): Name of the task.\n",
    "        props_path (str): Path to the properties file.\n",
    "        normalize (dict): Dictionary of properties to normalize.\n",
    "    \"\"\"\n",
    "    # SR is the fraction of molecules that have properties either decreased or increased as per the prompt\n",
    "    # measure novelty as the fraction of valid and successful molecules that are not in the training set\n",
    "    # measure similarity with input smiles as the average Tanimoto similarity between the input and the successful optimized molecules\n",
    "    # measure diversity as the average pairwise Tanimoto similarity among the successful optimized molecules\n",
    "    # measure synthetic accessibility as the average SAS score of the successful optimized molecules\n",
    "    # measure change percentage as the average percentage change in the properties of the successful and valid molecules\n",
    "\n",
    "    test_data = load_json(test_data_path)\n",
    "    test_data = [data for data in test_data if data['task'] == task and data['instr_setting'] == 'seen']\n",
    "    print(len(test_data))\n",
    "\n",
    "    property = task.split('+')\n",
    "    input_props = []\n",
    "    input_smiles = []\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        input_smiles.append(test_data[i]['source_smiles'])\n",
    "        input_prop = {}        \n",
    "        for prop in property:\n",
    "            input_prop[prop] = test_data[i]['properties'][prop]['source']\n",
    "        input_props.append(input_prop)\n",
    "\n",
    "    output_smiles = []\n",
    "    with open(output_path, 'r') as f:\n",
    "        for line in f:\n",
    "            output_smiles.append(line.strip())\n",
    "    \n",
    "    #output_smiles = output_smiles[:len(test_data)]\n",
    "    if not os.path.exists(props_path):\n",
    "        raise ValueError(f\"Properties file {props_path} does not exist. Run compute_props() to generate the properties file.\")\n",
    "\n",
    "    props_df = pd.read_csv(props_path)\n",
    "    props_df.set_index('smiles', inplace=True)\n",
    "\n",
    "    SR = diversity = 0\n",
    "    SAS = []\n",
    "    num_invalid = 0\n",
    "    num_seen_smiles = 0\n",
    "    most_optimized_smiles = []\n",
    "    perc_change = defaultdict(list)\n",
    "    norm_perc_change = defaultdict(list)\n",
    "    avg_change = defaultdict(list)\n",
    "    avg_value = defaultdict(list)\n",
    "    composite_change = []\n",
    "    norm_composite_change = []\n",
    "    similarity_with_input = []\n",
    "    num_inputs = len(test_data)\n",
    "\n",
    "    # save the most optimized smiles and their properties\n",
    "    most_optimized_smiles_props = []\n",
    "    unseen_smiles = set()\n",
    "\n",
    "    # compute properties for all smiles for each input\n",
    "    for i, opt_smiles in enumerate(output_smiles):\n",
    "        # if the row is empty, there were no smiles parsed by the process-output.ipynb\n",
    "        if not opt_smiles:\n",
    "            num_invalid += 1\n",
    "            continue\n",
    "\n",
    "        opt_smiles = opt_smiles.split(',')\n",
    "        \n",
    "        # otherwise, they were parseable, but could still be invalid based on rdkit\n",
    "        all_invalid_gen = True\n",
    "        output_props = defaultdict(list)\n",
    "        for smile in opt_smiles:\n",
    "            # assume that the properties were precomputed for all output smiles\n",
    "            # hence, if the smile is not in the properties dataframe, then prob it is invalid\n",
    "            if props_path and smile not in props_df.index:\n",
    "                if smile != 'Invalid':\n",
    "                    #print(i, smile)\n",
    "                    unseen_smiles.add(smile)\n",
    "                continue\n",
    "            # if there was any one valid generation out of at most 20 opt_smiles generated\n",
    "            all_invalid_gen = False\n",
    "            for prop in property:\n",
    "                output_props[prop].append(props_df.loc[smile, prop])\n",
    "            output_props['sim'].append(pair_similarity(input_smiles[i], smile, \"binary\"))\n",
    "        \n",
    "        num_invalid += 1 if all_invalid_gen else 0\n",
    "        # find the most optimized smiles based on the most improvement that satisfies the constraints\n",
    "        best_idx = find_best_optimized(input_props[i], output_props, property)\n",
    "        if best_idx is None:\n",
    "            continue\n",
    "    \n",
    "        all_props_desired = True\n",
    "        # increase the success count if the best optimized smile has better properties\n",
    "        for j, prop in enumerate(property):\n",
    "            #change = test_data[i]['properties'][prop]['change']\n",
    "            change = -1 if prop == 'mutagenicity' else 1\n",
    "            if np.sign(output_props[prop][best_idx] - input_props[i][prop]) != np.sign(change):\n",
    "                all_props_desired = False\n",
    "                break\n",
    "\n",
    "        # find_best_optimized should return the best optimized molecule that satisfies the constraints and\n",
    "        # has the most improvement in the properties\n",
    "        assert all_props_desired\n",
    "        \n",
    "        # if all_props_desired:\n",
    "        #     print_str = f\"{i}, {input_smiles[i]}\"\n",
    "        #     for prop in output_props.keys():\n",
    "        #         print_str += f\", {prop}: ({input_props[i].get(prop, 0)}, {output_props[prop][best_idx]})\"\n",
    "        #     print(print_str)\n",
    "\n",
    "        if all_props_desired:\n",
    "            most_optimized_smiles.append(opt_smiles[best_idx])\n",
    "            most_optimized_smiles_props.append({'opt_smiles': opt_smiles[best_idx], \n",
    "                                                'source_smiles': input_smiles[i],\n",
    "                                                'source_properties': input_props[i],\n",
    "                                                'optimized_properties': {prop: output_props[prop][best_idx] for prop in property}})\n",
    "            #SR += 1\n",
    "            if opt_smiles[best_idx] in seen_smiles:\n",
    "                num_seen_smiles += 1\n",
    "            similarity_with_input.append(output_props['sim'][best_idx])\n",
    "            try:\n",
    "                SAS.append(sas(opt_smiles[best_idx]))\n",
    "            except:\n",
    "                pass\n",
    "            for prop in property:\n",
    "                avg_value[prop].append(output_props[prop][best_idx])\n",
    "                input_val = input_props[i].get(prop, 0)\n",
    "                output_val = output_props[prop][best_idx]\n",
    "                # we can compute the absolute change in the property because\n",
    "                # we already ensured that this is optimized\n",
    "                avg_change[prop].append(abs(output_val - input_val))\n",
    "                \n",
    "                if input_val == 0:\n",
    "                    perc_change[prop].append((output_val - 0.1)/0.1)\n",
    "                else:\n",
    "                    perc_change[prop].append(abs(input_val - output_val) / abs(input_val))\n",
    "\n",
    "                # for percentage change, compute an unnormalized and normalized change\n",
    "                if normalize and prop in normalize:\n",
    "                    input_val = normalize_prop(input_val, *normalize[prop])\n",
    "                    output_val = normalize_prop(output_val, *normalize[prop])\n",
    "    \n",
    "                    if input_val == 0:\n",
    "                        norm_perc_change[prop].append((output_val - 0.1)/0.1)\n",
    "                    else:\n",
    "                        norm_perc_change[prop].append(abs(input_val - output_val) / abs(input_val))\n",
    "\n",
    "            composite_change.append(np.mean([perc_change[prop][-1] for prop in property]))\n",
    "            if normalize:\n",
    "                norm_composite_change.append(np.mean([norm_perc_change[prop][-1] for prop in property]))\n",
    "            \n",
    "    fp_sim = compute_FP_sim(most_optimized_smiles)\n",
    "    diversity = 1 - np.mean(fp_sim[np.triu_indices(len(fp_sim), k=1)])\n",
    "    num_success = len(most_optimized_smiles)\n",
    "    num_unseen = num_success - num_seen_smiles\n",
    "    num_valid = num_inputs - num_invalid\n",
    "    #print(len(unseen_smiles))\n",
    "    \n",
    "    SR = num_success / num_inputs\n",
    "    SR_V = num_success / num_valid if num_valid else 0\n",
    "    validity = num_valid / num_inputs\n",
    "\n",
    "    ret = {\n",
    "        \"SR\": SR*100,\n",
    "        \"Sim\": np.mean(similarity_with_input),\n",
    "        \"RI\": np.mean(composite_change),\n",
    "        \"Val\": validity*100,\n",
    "        \"SR (V)\": SR_V*100,\n",
    "        \"Nov\": (num_unseen / num_success) * 100 if num_success else 0,\n",
    "        \"Div\": diversity,\n",
    "        \"SAS\": np.mean(SAS),\n",
    "        \"Norm RI\": np.nanmean(norm_composite_change)\n",
    "    }\n",
    "    for prop in property:\n",
    "        ret[f\"{prop}-APS\"] = np.mean(avg_value[prop])\n",
    "        ret[f\"{prop}-impv\"] = np.mean(avg_change[prop])\n",
    "        ret[f\"{prop}-impv%\"] = np.mean(perc_change[prop]) * 100\n",
    "        if normalize:\n",
    "            ret[f\"{prop}-impv(n)%\"] = np.mean(norm_perc_change[prop]) * 100\n",
    "\n",
    "    return ret, most_optimized_smiles_props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Evaluation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "                  0\n",
      "SR            85.80\n",
      "Sim            0.59\n",
      "RI             4.78\n",
      "Val           99.60\n",
      "SR (V)        86.14\n",
      "Nov          100.00\n",
      "Div            0.84\n",
      "SAS            2.93\n",
      "Norm RI         nan\n",
      "bbbp-APS       0.75\n",
      "bbbp-impv      0.37\n",
      "bbbp-impv%   140.87\n",
      "drd2-APS       0.19\n",
      "drd2-impv      0.18\n",
      "drd2-impv% 1,188.92\n",
      "qed-APS        0.40\n",
      "qed-impv       0.19\n",
      "qed-impv%    104.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sk21/lib/python3.6/site-packages/ipykernel_launcher.py:180: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/van/Developer/workspace/gellmo/GeLLMO')  # Go back to the root directory of the project\n",
    "seen_smiles = np.loadtxt(f\"data/unique_mols_in_one_ds_pairs.txt\", dtype=str, comments=None)\n",
    "seen_smiles = set(seen_smiles)\n",
    "\n",
    "task = 'bbbp+drd2+qed'\n",
    "test_data_path = 'test.json'\n",
    "output_path = f\"examples/{task}-smiles.csv\"\n",
    "admet_props_path = f\"examples/{task}-admet_props.csv\"\n",
    "props_path = f\"examples/{task}-props.csv\"\n",
    "# generate the properties for the optimized smiles\n",
    "compute_props(output_path, admet_props_path, props_path)\n",
    "# compute the metrics for the optimized smiles\n",
    "ret, _ = compute_metrics(test_data_path, output_path, seen_smiles, task, props_path, None)\n",
    "# print the metrics converting to 2 decimal places\n",
    "print(pd.DataFrame(ret, index=[0]).T.round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sk21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
