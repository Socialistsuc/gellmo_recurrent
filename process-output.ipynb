{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66cdeb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d809f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def load_json(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(file, data):\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f29ecf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to canonicalize SMILES\n",
    "def canonicalize_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        return Chem.MolToSmiles(mol, canonical=True)\n",
    "    except:\n",
    "        pass  # Handle invalid SMILES strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980310d6-a321-4516-b887-49d9b3c0983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_output(output_file, model_id) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts the list of SMILES strings from the json response output of LLMs\n",
    "    :param output_file: str, path to the json file containing the output\n",
    "    :param model_id: str, the model id of the LLM used to differentiate the json object structure\n",
    "    \"\"\"\n",
    "    with open(output_file, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Updated SMILES regex pattern to be more robust\n",
    "    smiles_pattern = r\"<SMILES>\\s*((?:[A-Za-z0-9@+\\-\\[\\]\\(\\)\\\\\\/%=#\\$:.]+))\\s*</SMILES>\"\n",
    "    optimized_smiles = []\n",
    "    matches = None\n",
    "\n",
    "    for i, entry in enumerate(data):\n",
    "        if model_id in ['llasmol']:\n",
    "            response_text = \" \".join(entry.get(\"output\", [\"\"]))\n",
    "        elif model_id in ['claude']:\n",
    "            response_text = entry.get(\"output\", \"\")\n",
    "        elif model_id in ['mistral', 'chemllm', 'llama']:\n",
    "            response_tag = \"[/INST]\\n%%% Response:\"\n",
    "            responses = entry.get(\"response\", [])\n",
    "            # by mistake we put the prompt as well in the response, so we have input smiles as well\n",
    "            # so we need to extract the output smiles only from the response\n",
    "            if response_tag in responses[0]:\n",
    "                response_text = []\n",
    "                for response in responses:\n",
    "                    if response_tag in response:\n",
    "                        response_text.append(response.split(response_tag)[1].split('<<SYS>>')[0])\n",
    "                response_text = \" \".join(response_text)\n",
    "                #print(i, response_text)\n",
    "            else:\n",
    "                response_text = \" \".join(responses)\n",
    "        else:\n",
    "            response_text = entry\n",
    "\n",
    "        matches = re.findall(smiles_pattern, response_text)\n",
    "\n",
    "        if matches:\n",
    "            # Use the last match in case there are multiple SMILES strings\n",
    "            opts = set()\n",
    "            for match in matches:\n",
    "                opts.add(match.strip())\n",
    "            optimized_smiles.append(' '.join(list(opts)))\n",
    "            #print(i, opts)\n",
    "        else:\n",
    "            optimized_smiles.append(\"None\")\n",
    "\n",
    "    return optimized_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17bf9ba9-ef75-4f3b-80f0-c7531a7ad1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output_llms(raw_output_path, output_path, model_id):\n",
    "    \"\"\"\n",
    "    Process the output of LLMs to extract the SMILES strings\n",
    "    :param raw_output_path: str, path to the raw output json file\n",
    "    :param output_path: str, path to save the extracted SMILES strings\n",
    "    :param model_id: str, the model id of the LLM used to differentiate the json format\n",
    "        Accepted values: ['llasmol', 'claude', 'mistral', 'chemllm', 'llama']\n",
    "    \"\"\"\n",
    "    # for llms, we need to extract the SMILES from json file and return all the SMILES\n",
    "    optimized_smiles = extract_output(raw_output_path, model_id)\n",
    "\n",
    "    output_smiles = []\n",
    "    for i in range(len(optimized_smiles)):\n",
    "        tmp_smiles = optimized_smiles[i].split()\n",
    "        opt_smiles = set()\n",
    "        for smile in tmp_smiles:\n",
    "            # first check if the smile is valid\n",
    "            canonical_smile = None\n",
    "            try:\n",
    "                canonical_smile = Chem.MolToSmiles(Chem.MolFromSmiles(smile))\n",
    "                opt_smiles.add(canonical_smile)\n",
    "            except:\n",
    "                pass\n",
    "        output_smiles.append(','.join(opt_smiles))\n",
    "    \n",
    "    # save the list of SMILES as a txt file\n",
    "    np.savetxt(output_path, output_smiles, fmt='%s', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fa1d1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wgy/workspace/local/anaconda3/envs/gellmo/lib/python3.11/site-packages/chemprop/utils.py:473: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vars(torch.load(path, map_location=lambda storage, loc: storage)[\"args\"]),\n",
      "/data/home/wgy/workspace/local/anaconda3/envs/gellmo/lib/python3.11/site-packages/chemprop/utils.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(path, map_location=lambda storage, loc: storage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Moving model to cuda\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Moving model to cuda\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Moving model to cuda\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Moving model to cuda\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Moving model to cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/wgy/workspace/local/anaconda3/envs/gellmo/lib/python3.11/site-packages/chemprop/utils.py:418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(path, map_location=lambda storage, loc: storage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Moving model to cuda\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Moving model to cuda\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Moving model to cuda\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Moving model to cuda\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Moving model to cuda\n"
     ]
    }
   ],
   "source": [
    "from admet_ai import ADMETModel\n",
    "model = ADMETModel(num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb003d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_props(smiles_path, props_path):\n",
    "    \"\"\"\n",
    "    Generates properties for the preprocessed SMILES files using the ADMET model\n",
    "    :param smiles_path: str, path to the preprocessed SMILES file\n",
    "    :param output_path: str, path to save the properties as a csv file\n",
    "    \"\"\"\n",
    "\n",
    "    # load the preprocessed SMILES\n",
    "    smiles = []\n",
    "    with open(smiles_path, 'r') as f:\n",
    "        for line in f:\n",
    "            smiles += line.strip().split(',')\n",
    "    # remove duplicates\n",
    "    smiles = set(smiles)\n",
    "    print(f\"Number of preprocessed SMILES: {len(smiles)}\")\n",
    "    smiles = [canonicalize_smiles(smile) for smile in smiles]\n",
    "    #print(len(smiles))\n",
    "    smiles = [smile for smile in smiles if smile is not None]\n",
    "    print(f\"Number of postprocessed SMILES: {len(smiles)}\")\n",
    "    # compute properties\n",
    "    props = model.predict(smiles)\n",
    "    # save the props as a csv\n",
    "    props_df = pd.DataFrame(props)\n",
    "    props_df.reset_index(inplace=True)\n",
    "    # rename BBB_Martins to BBBP\n",
    "    props_df.rename(columns={'index': 'smiles', 'BBB_Martins': 'bbbp', 'AMES': 'mutagenicity', 'HIA_Hou': 'hia'}, inplace=True)\n",
    "    props_df = props_df[['smiles', 'bbbp', 'mutagenicity', 'hia']].round(2)\n",
    "    props_df.to_csv(props_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021f0d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test/bbbp+drd2+plogp+qed-smiles.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Use `model_id` = 'mistral' or 'llama' for all GeLLMO models using Mistral or LLama as the base LLM, respectively.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Use `model_id` = 'llasmol' or 'claude' for outputs of LLaSMoL or Claude, respectively.\u001b[39;00m\n\u001b[32m      3\u001b[39m process_output_llms(\u001b[33m\"\u001b[39m\u001b[33mtest/bbbp+drd2+plogp+qed_response.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtest/bbbp+drd2+plogp+qed_smiles.csv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmistral\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m generate_props(\u001b[33m\"\u001b[39m\u001b[33mtest/bbbp+drd2+plogp+qed-smiles.csv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtest/bbbp+drd2+plogp+qed-admet_props.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mgenerate_props\u001b[39m\u001b[34m(smiles_path, props_path)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# load the preprocessed SMILES\u001b[39;00m\n\u001b[32m      9\u001b[39m smiles = []\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(smiles_path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[32m     12\u001b[39m         smiles += line.strip().split(\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/local/anaconda3/envs/gellmo/lib/python3.11/site-packages/IPython/core/interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, *args, **kwargs)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'test/bbbp+drd2+plogp+qed-smiles.csv'"
     ]
    }
   ],
   "source": [
    "# Use `model_id` = 'mistral' or 'llama' for all GeLLMO models using Mistral or LLama as the base LLM, respectively.\n",
    "# Use `model_id` = 'llasmol' or 'claude' for outputs of LLaSMoL or Claude, respectively.\n",
    "process_output_llms(\"test/bbbp+drd2+plogp+qed_response.json\", \"test/bbbp+drd2+plogp+qed-smiles.csv\", \"mistral\")\n",
    "generate_props(\"test/bbbp+drd2+plogp+qed-smiles.csv\", \"test/bbbp+drd2+plogp+qed-admet_props.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gellmo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
